{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0367e8",
   "metadata": {},
   "source": [
    "# LASSO + EEMD + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import date\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "import warnings\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "\n",
    "#Save the log\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import tempfile\n",
    "\n",
    "# Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# EEMD\n",
    "from PyEMD import EEMD\n",
    "\n",
    "# LSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Optimize\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "# Metric \n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea5a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c7869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minus\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "# Hangul\n",
    "plt.rcParams['font.family'] = 'Serif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb05a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eemd_fit(df):\n",
    "    # Define signal\n",
    "    t = np.array(df['Date']) # x-axis\n",
    "    s = np.array(df['y']) # y-axis\n",
    "\n",
    "    eemd = EEMD() \n",
    "    eemd.noise_seed(1234)\n",
    "\n",
    "    eIMFs = eemd.eemd(s, t, max_imf=-1) \n",
    "    nIMFs = eIMFs.shape[0] \n",
    "    \n",
    "    imfs, residue = eemd.get_imfs_and_residue()\n",
    "    \n",
    "    all_eIMFs_df = pd.DataFrame(eIMFs).transpose() \n",
    "    all_eIMFs_df[nIMFs] = residue \n",
    "    all_eIMFs_df.insert(0, 'Date', df['Date']) \n",
    "\n",
    "    plt.figure(figsize=(12, nIMFs*2), dpi=300) \n",
    "    for i in range(nIMFs):\n",
    "        plt.subplot(nIMFs+1, 1, i+1) \n",
    "        plt.plot(df['Date'], all_eIMFs_df[i], 'g')\n",
    "        plt.title('IMF '+str(i+1), fontsize=10)\n",
    "\n",
    "    # Residue plot\n",
    "    plt.subplot(nIMFs+1, 1, nIMFs+1)\n",
    "    plt.plot(df['Date'], all_eIMFs_df[nIMFs], 'r')\n",
    "    plt.title('Residue', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return all_eIMFs_df, nIMFs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_eIMFs(all_eIMFs_df, nIMFs):\n",
    "    all_eIMFs_dict = {}\n",
    "\n",
    "    for i in range(nIMFs+1):\n",
    "        tmp_df = all_eIMFs_df[['Date', i]] \n",
    "        tmp_df.columns=['Date', 'y'] \n",
    "        all_eIMFs_dict[f'eIMFs_{i}'] = tmp_df\n",
    "                            # df.columns = ['Date', 'y']\n",
    "    return all_eIMFs_dict # {eIMFs_1: df1, eIMFs_2: df2, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ac18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_feature_selection(df):\n",
    "    tmp_df = df.copy()\n",
    "\n",
    "    tmp_df = df[df['Date']<'2022-08-01']\n",
    "    tmp_df = df.drop(columns=['Date','Product', '년월'])\n",
    "\n",
    "    y = tmp_df.loc[:, 'y']\n",
    "    X = tmp_df.drop(columns='y')\n",
    "    \n",
    "    lasso = Lasso(alpha=1) \n",
    "    lasso.fit(X, y)\n",
    "    \n",
    "\n",
    "    coefficients = pd.Series(lasso.coef_, index=X.columns)\n",
    "    selected_var = coefficients[coefficients != 0]\n",
    "\n",
    "    \n",
    "    return selected_var.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be73251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(product_df, eIMF_df, time_steps): \n",
    "    tmp_df = product_df.copy()\n",
    "    tmp_df['y'] = eIMF_df['y']\n",
    "    \n",
    "    selected_features = lasso_feature_selection(tmp_df)\n",
    " \n",
    "    selected_features.insert(0, 'y') \n",
    "    \n",
    "    global n_features \n",
    "    n_features = len(selected_features)\n",
    "    target_idx = selected_features.index('y')\n",
    "    \n",
    "    filtered_df = product_df.filter(selected_features)  \n",
    "    filtered_df['y'] = eIMF_df['y'] \n",
    "    \n",
    "    train_end = len(product_df[product_df['Date']<'2022-07-01'])\n",
    "    # Scaling\n",
    "    sc = StandardScaler() \n",
    "    y_train_scaled = sc.fit_transform(filtered_df.iloc[:train_end, :])\n",
    "    \n",
    "    X_train = [] \n",
    "    y_train = []\n",
    "    for i in range(time_steps, train_end):\n",
    "        X_train.append(y_train_scaled[i-time_steps:i, :])  \n",
    "        y_train.append(y_train_scaled[i, target_idx]) \n",
    "        \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], n_features)) \n",
    "    \n",
    "    y_test_scaled = sc.transform(filtered_df.iloc[train_end:, :])\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = product_df.iloc[train_end+time_steps:].copy()\n",
    "    y_test['y'] = eIMF_df['y'].iloc[train_end+time_steps:]\n",
    "    \n",
    "    y_test['y_norm'] = y_test_scaled[time_steps:, target_idx]  \n",
    "    \n",
    "    for i in range(time_steps, len(y_test_scaled)):\n",
    "        X_test.append(y_test_scaled[i-time_steps:i, :])\n",
    "    \n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], n_features))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, sc, target_idx, selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "   \n",
    "    model.add(LSTM(units=hp.Int('units_1', min_value=128, max_value=320, step=64),\n",
    "                   activation='tanh',\n",
    "                   return_sequences=True, \n",
    "                   input_shape=(None, n_features)))\n",
    "    \n",
    "    model.add(LSTM(units=hp.Int('units_2', min_value=64, max_value=256, step=32),\n",
    "                   activation='tanh',\n",
    "                   return_sequences=False))\n",
    "\n",
    "    model.add(Dense(units=hp.Int('dense_unit', min_value=16, max_value=128, step=16),\n",
    "                    activation='tanh'))\n",
    "        \n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mse'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def optimize_model(X_train, y_train, X_test, sc, epochs, trials, target_idx):\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        tuner = RandomSearch(\n",
    "            build_model,\n",
    "            objective='loss',\n",
    "            max_trials= trials,\n",
    "            directory=temp_dir,\n",
    "            project_name='temp_project')\n",
    "\n",
    "    tuner.search_space_summary()\n",
    "    tuner.search(X_train, y_train,\n",
    "                 epochs=epochs,\n",
    "                 batch_size=8)\n",
    "\n",
    "    tuner.results_summary()\n",
    "\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "    pred = best_model.predict(X_test) \n",
    "    pred_norm = pred \n",
    "    \n",
    "    pred_expanded = np.zeros((pred.shape[0], n_features))\n",
    "    pred_expanded[:,target_idx] = pred.ravel() \n",
    "    \n",
    "    pred = sc.inverse_transform(pred_expanded)\n",
    "    pred = pred[:, target_idx]  \n",
    "    \n",
    "    best_model.summary()\n",
    "\n",
    "    return best_model, pred, pred_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ed2da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(best_model, product_code, idx):\n",
    "    path = f'./Result/EEMD+LASSO+LSTM/Model/{product_code}_{idx}.h5'\n",
    "    best_model.save(path)\n",
    "    return \n",
    "\n",
    "def use_model(X_test, product_code, idx, target_idx, sc):\n",
    "    path = f'./Result/EEMD+LASSO+LSTM_50_20/Model/{product_code}_{idx}.h5'\n",
    "    best_model = tf.keras.models.load_model(path)\n",
    "    \n",
    "    pred = best_model.predict(X_test) \n",
    "    pred_norm = pred \n",
    "    \n",
    "    pred_expanded = np.zeros((pred.shape[0], n_features))\n",
    "    pred_expanded[:,target_idx] = pred.ravel()  \n",
    "    \n",
    "    pred = sc.inverse_transform(pred_expanded)\n",
    "    pred = pred[:, target_idx]  \n",
    "    \n",
    "    best_model.summary()\n",
    "\n",
    "    return best_model, pred, pred_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be0121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(selected_features, product_code, idx):\n",
    "    \n",
    "    file_path = f'./Result/EEMD+LASSO+LSTM/Features/{product_code}_{idx}.pkl'\n",
    "    \n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(selected_features, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a404016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EEMD_LSTM(product_df, all_eIMFs_dict, time_steps, epochs, trials, saved_model: bool):\n",
    "    residue_epochs = epochs\n",
    "    pred_dict = {}\n",
    "    product_code = product_df['Product'].unique()[0]\n",
    "    imf_feature_dict = {}\n",
    "\n",
    "    for idx, i in enumerate(all_eIMFs_dict.keys()):\n",
    "        print(f'--------Total: 0~{len(all_eIMFs_dict)-1} eIMFs, Now: {i} --------')\n",
    "        \n",
    "        eIMF_df = all_eIMFs_dict[i]\n",
    "        \n",
    "        X_train, y_train, X_test, y_test, sc, target_idx, selected_features = split_data(product_df, eIMF_df, time_steps)\n",
    "        imf_feature_dict[i] = selected_features\n",
    "        # use the existing model\n",
    "        if saved_model:\n",
    "            best_model, pred, pred_norm = use_model(X_test, product_code, idx, target_idx, sc)\n",
    "        # save the new model\n",
    "        else:\n",
    "            best_model, pred, pred_norm = optimize_model(X_train, y_train, X_test, sc, epochs, trials, target_idx)\n",
    "            save_model(best_model, product_code, idx)\n",
    "        \n",
    "            if idx != len(all_eIMFs_dict)-2:\n",
    "                epochs = max(1, round(epochs*0.8)) \n",
    "            # Prevent overfitting\n",
    "            else: \n",
    "                epochs = residue_epochs\n",
    "        \n",
    "        y_test.reset_index(drop=True, inplace=True)\n",
    "        pred_df = pd.DataFrame({'Pred': pred.reshape(-1) ,'Pred_norm': pred_norm.reshape(-1)})\n",
    "        res_df = pd.concat([y_test, pred_df], axis=1)\n",
    "        \n",
    "        res_df.set_index('Date', inplace=True)\n",
    "        res_df.index = pd.to_datetime(res_df.index)\n",
    "        # res_df: ['y', 'y_norm', 'Pred', 'Pred_norm'], index='Date'\n",
    "        pred_dict[i] = res_df\n",
    "\n",
    "    return pred_dict, imf_feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40503729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_result_df(pred_dict):\n",
    "    eIMF_result_df = pd.DataFrame()\n",
    "    for tmp_df in pred_dict.values():\n",
    "        eIMF_result_df = pd.concat([eIMF_result_df, tmp_df], axis=1)\n",
    "        \n",
    "    pred_df = eIMF_result_df['Pred'].sum(axis=1)\n",
    "    actual_df = eIMF_result_df['y'].sum(axis=1)\n",
    "    \n",
    "    all_result_df = pd.DataFrame({'Pred': pred_df, 'y': actual_df})\n",
    "    all_result_df.loc[all_result_df['Pred']<0, 'Pred']=0 \n",
    "    \n",
    "    return eIMF_result_df, all_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8fe2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_pred_plot(product_code, pred_dict, all_result_df, metric_df):\n",
    "    \"\"\"\n",
    "    Plot the actual vs predition and save the figure in the given directory\n",
    "    \"\"\"\n",
    "    \n",
    "    pred_dict['all_result'] = all_result_df\n",
    "    \n",
    "    save_path = os.path.join(\"Result\", \"EEMD+LASSO+LSTM\", product_code)\n",
    "        \n",
    "    for i, res_df in enumerate(pred_dict.values()):\n",
    "        img_n = len(pred_dict)\n",
    "        title = f\"eIMF{i+1}\"\n",
    "        \n",
    "        if i == img_n-2: title = \"Residue\"\n",
    "        actual = res_df['y']\n",
    "        pred = res_df['Pred']\n",
    "        save_name = f'{product_code}_eIMF_{i+1}'\n",
    "        \n",
    "        if i == img_n-1: # All result\n",
    "            title = f\"{product_code}-All Result\"\n",
    "            save_name = f'{product_code}_all_result'\n",
    "\n",
    "        # Pred-Actual Plot\n",
    "        plt.figure(figsize=(16, 8), dpi=300)\n",
    "        plt.title(title, fontsize=24)\n",
    "        plt.xlabel(\"Date\", fontsize=18)\n",
    "        plt.ylabel(\"Order Demand\", fontsize=18)\n",
    "        plt.plot(res_df.index, actual, label ='Actual', color='r')\n",
    "        plt.plot(res_df.index, pred, label='Prediction',color='b')\n",
    "\n",
    "        plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        \n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        # save the figure\n",
    "        plt.savefig(os.path.join(save_path, save_name+'.png'), dpi=300)\n",
    "        plt.show()\n",
    "        \n",
    "    # Metric\n",
    "    metric_df.to_csv(os.path.join(save_path, f'{product_code}_metric.csv'), encoding=\"utf-8-sig\")\n",
    "    all_result_df.to_csv(os.path.join(save_path, f'{product_code}_total_result.csv'), encoding=\"utf-8-sig\")\n",
    "    \n",
    "    del pred_dict['all_result']\n",
    "    \n",
    "    file_path = os.path.join(save_path, f'{product_code}_eIMF_dict.pkl')\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(pred_dict, file)\n",
    "        \n",
    "    plt.close('all') # close all figures to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d211ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_eIMF(product_code):\n",
    "    # Set up the path\n",
    "    directory_path = os.path.join(\"Result\", \"EEMD+LASSO+LSTM\", product_code)\n",
    "    file_path = os.path.join(directory_path, f'{product_code}_eIMF_dict.pkl')\n",
    "    \n",
    "    # Load the dictionary\n",
    "    with open(file_path, 'rb') as file:\n",
    "        eIMF_dict = pickle.load(file)\n",
    "    \n",
    "    # Create new dictionary without last item\n",
    "    eIMF_dict = {k: eIMF_dict[k] for k in list(eIMF_dict)}\n",
    "    n = len(eIMF_dict)  # Number of dataframes after filtering\n",
    "    \n",
    "    # Create subplots for each plot\n",
    "    fig, axs = plt.subplots(n, 1, figsize=(10, 1.5*n), dpi=300, sharex=True)  \n",
    "    \n",
    "    for idx, (key, df) in enumerate(eIMF_dict.items()):\n",
    "        sns.lineplot(data=df, x=df.index, y='y', ax=axs[idx], color='r', linestyle='solid', label='Actual')\n",
    "        sns.lineplot(data=df, x=df.index, y='Pred', ax=axs[idx], color='b', linestyle='dashed', label='Predicted')\n",
    "        \n",
    "        axs[idx].set_xlabel('')\n",
    "\n",
    "        if idx == n - 1:\n",
    "            axs[idx].set_ylabel(\"Residue\", fontsize=14, rotation=0, labelpad=40)\n",
    "            axs[idx].yaxis.set_label_coords(-0.11, 0.5) \n",
    "            axs[idx].legend(loc='lower left')\n",
    "        else:\n",
    "            axs[idx].set_ylabel(f'eIMF{idx + 1}', fontsize=14, rotation=0, labelpad=40) \n",
    "            axs[idx].yaxis.set_label_coords(-0.11, 0.5)  \n",
    "        \n",
    "        if idx == 0:\n",
    "            axs[idx].legend(loc='lower right')\n",
    "        else:\n",
    "            axs[idx].legend_.remove() \n",
    "        \n",
    "    # Adjust layout so plots do not overlap\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure to the specified path\n",
    "    img_file_path = os.path.join(directory_path, f\"{product_code}_eIMF_plot.png\")\n",
    "    plt.savefig(img_file_path, dpi=300)  # Set the resolution to your preference\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / (actual+1)))\n",
    "\n",
    "def nrmse(y_true, y_pred):\n",
    "    mse = root_mean_squared_error(y_true, y_pred)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nrmse = mse / target_mean\n",
    "    return nrmse\n",
    "\n",
    "def nmae(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nmae = mae / target_mean\n",
    "    return nmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83451baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(pred_df):\n",
    "\n",
    "    metric_df = pd.DataFrame(columns=['MAPE',\n",
    "                                      'RMSE',\n",
    "                                      'MAE',\n",
    "                                      'NRMSE',\n",
    "                                      'NMAE',\n",
    "                                      'R2'])\n",
    "    \n",
    "    actual = pred_df['y']\n",
    "    pred = pred_df['Pred']\n",
    "\n",
    "    MAPE = mape(actual, pred) \n",
    "    RMSE = root_mean_squared_error(actual, pred) \n",
    "    MAE = mean_absolute_error(actual,pred) \n",
    "    NRMSE = nrmse(actual,pred) \n",
    "    NMAE = nmae(actual,pred) \n",
    "    R2 = r2_score(actual, pred)\n",
    "\n",
    "    tmp_df = pd.DataFrame({'MAPE':[round(MAPE, 4)],\n",
    "                           'RMSE':[round(RMSE, 4)],\n",
    "                           'MAE':[round(MAE, 4)],\n",
    "                           'NRMSE':[round(NRMSE, 4)],\n",
    "                           'NMAE':[round(NMAE, 4)],\n",
    "                           'R2': [round(R2, 4)]})\n",
    "\n",
    "    metric_df = pd.concat([metric_df, tmp_df])\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e560ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_metric_df(pred_dict, all_result_df):\n",
    "\n",
    "    metric_df = pd.DataFrame(columns=['MAPE', 'RMSE', 'MAE', 'NRMSE', 'NMAE', 'R2'])\n",
    "    for i, pred_df in pred_dict.items():\n",
    "        imf_df = calculate_metrics(pred_df)\n",
    "        metric_df = pd.concat([metric_df, imf_df])\n",
    "    \n",
    "    imf_idx = pd.Index(['eIMF_' + str(i+1) for i in range(len(pred_dict))]) # changed result_dict to pred_dict\n",
    "    metric_df.index = imf_idx # Assign the created index to metric_df\n",
    "    \n",
    "    metric_df = pd.concat([metric_df, calculate_metrics(all_result_df)], axis=0)\n",
    "    metric_df = metric_df.rename(index={metric_df.index[-1]: 'All'}) \n",
    "    \n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce9ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_EEMD_LSTM(product_code, time_steps=30, epochs=50, optimize_trials=5):\n",
    "    start_time = time.time()\n",
    "    product_df = df[df['Product']== product_code].reset_index(drop=True)\n",
    "    \n",
    "    all_eIMFs_df, nIMFs = eemd_fit(product_df)\n",
    "    all_eIMFs_dict = extract_eIMFs(all_eIMFs_df, nIMFs)\n",
    "    \n",
    "    pred_dict, imf_feature_dict = EEMD_LSTM(product_df, all_eIMFs_dict, time_steps, epochs, optimize_trials, saved_model=True) #dictionary, time_steps, epochs\n",
    "    eIMF_result_df, all_result_df = make_all_result_df(pred_dict)\n",
    "\n",
    "    metric_df = make_metric_df(pred_dict, all_result_df)\n",
    "    # Pred_Actual Plot\n",
    "    actual_pred_plot(product_code, pred_dict,  all_result_df, metric_df)\n",
    "\n",
    "    elapsed_time_seconds = time.time() - start_time\n",
    "    elapsed_time_minutes = elapsed_time_seconds / 60\n",
    "    print(\"실행 시간: {:.2f} 분\".format(elapsed_time_minutes))\n",
    "    return metric_df, imf_feature_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5269ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb732a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"../Data/dataset.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25559e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set_seed(1234)\n",
    "feature_dict = {}\n",
    "all_metric = pd.DataFrame()\n",
    "\n",
    "target_code = ['Office Product', 'Packaging material', 'Pharmaceuticals']\n",
    "for code in target_code:\n",
    "   \n",
    "    print(\"==================================\")\n",
    "    print(f\"============ { code } ============\")\n",
    "    print(\"==================================\")\n",
    "\n",
    "    tmp_metric, imf_feature_dict = execute_EEMD_LSTM(code)\n",
    "    feature_dict[code] = imf_feature_dict\n",
    "    all_metric = pd.concat([all_metric, tmp_metric])\n",
    "    \n",
    "prod_metric_df = all_metric.loc['All']\n",
    "prod_metric_df.index = target_code\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e962c306",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c5984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of variables\n",
    "plt.figure(figsize=(10, 6), dpi=300)  \n",
    "\n",
    "for product, imf_dict in feature_dict.items():\n",
    "    x = list(range(1, len(imf_dict) + 1))  \n",
    "    y = [len(vars)-1 for vars in imf_dict.values()]  \n",
    "    plt.plot(x, y, label=product, marker='s', ms=3)  \n",
    "\n",
    "xticks_labels = [str(i) for i in range(1, len(imf_dict))] + [\"Residue\"]\n",
    "plt.xticks(ticks=range(1, len(imf_dict) + 1), labels=xticks_labels, fontsize=14)\n",
    "\n",
    "plt.ylabel(\"Number of Variables\", fontsize=18)\n",
    "plt.xlabel(\"eIMF\", fontsize=18)\n",
    "plt.legend(fontsize=16)\n",
    "\n",
    "save_path = \"./var_plot.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight') \n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eemd",
   "language": "python",
   "name": "eemd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
