{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0367e8",
   "metadata": {},
   "source": [
    "# EEMD + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import date\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "import warnings\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "\n",
    "#Save the log\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import tempfile\n",
    "\n",
    "# EEMD\n",
    "from PyEMD import EEMD\n",
    "\n",
    "# LSTM\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Optimize\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "# Metric \n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1741b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e28dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minus\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "# font\n",
    "plt.rcParams['font.family'] = 'Serif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb05a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eemd_fit(df):\n",
    "    # Define signal\n",
    "    t = np.array(df['Date']) # x-axis\n",
    "    s = np.array(df['y']) # y-axis\n",
    "\n",
    "    eemd = EEMD()\n",
    "    eemd.noise_seed(1234)\n",
    "    \n",
    "    eIMFs = eemd.eemd(s, t, max_imf=-1) \n",
    "    nIMFs = eIMFs.shape[0] \n",
    "\n",
    "    imfs, residue = eemd.get_imfs_and_residue()\n",
    "\n",
    "    all_eIMFs_df = pd.DataFrame(eIMFs).transpose() \n",
    "    all_eIMFs_df[nIMFs] = residue \n",
    "    all_eIMFs_df.insert(0, 'Date', df['Date']) \n",
    "    \n",
    "    plt.figure(figsize=(12, nIMFs*2), dpi=300) \n",
    "    for i in range(nIMFs):\n",
    "        plt.subplot(nIMFs+1, 1, i+1) \n",
    "        plt.plot(df['Date'], all_eIMFs_df[i], 'g')\n",
    "        plt.title('IMF '+str(i+1), fontsize=10)\n",
    "\n",
    "    # Residue plot\n",
    "    plt.subplot(nIMFs+1, 1, nIMFs+1)\n",
    "    plt.plot(df['Date'], all_eIMFs_df[nIMFs], 'r')\n",
    "    plt.title('Residue', fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return all_eIMFs_df, nIMFs # eIMF+Residue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_eIMFs(all_eIMFs_df, nIMFs):\n",
    "    all_eIMFs_dict = {}\n",
    "\n",
    "    for i in range(nIMFs+1):\n",
    "        tmp_df = all_eIMFs_df[['Date', i]] \n",
    "        tmp_df.columns=['Date', 'y'] \n",
    "        all_eIMFs_dict[f'eIMFs_{i}'] = tmp_df \n",
    "                            # df.columns = ['Date', 'y']\n",
    "    return all_eIMFs_dict # {eIMFs_1: df1, eIMFs_2: df2, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be73251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(product_df, eIMF_df, time_steps): \n",
    "\n",
    "    train_end = len(product_df[product_df['Date']<'2022-07-01'])\n",
    "    \n",
    "    features = product_df.drop(['Date','Product','년월'], axis=1).columns.tolist()\n",
    "    \n",
    "    global n_features\n",
    "    n_features = len(features)\n",
    "    \n",
    "    filtered_df = product_df.filter(features)  \n",
    "    filtered_df['y'] = eIMF_df['y']\n",
    "    target_idx = filtered_df.columns.tolist().index('y')\n",
    "    \n",
    "    sc = MinMaxScaler() \n",
    "    y_train_scaled = sc.fit_transform(filtered_df.iloc[:train_end, :])\n",
    "    \n",
    "    X_train = [] \n",
    "    y_train = []\n",
    "    \n",
    "    for i in range(time_steps, train_end):\n",
    "        X_train.append(y_train_scaled[i-time_steps:i, :])  \n",
    "        y_train.append(y_train_scaled[i, target_idx])  \n",
    "        \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], n_features)) \n",
    "    \n",
    "    y_test_scaled = sc.transform(filtered_df.iloc[train_end:, :])\n",
    "    \n",
    "    X_test = []\n",
    "    y_test = product_df.iloc[train_end+time_steps:].copy()\n",
    "    y_test['y'] = eIMF_df['y'].iloc[train_end+time_steps:]\n",
    "    \n",
    "    y_test['y_norm'] = y_test_scaled[time_steps:, target_idx]  \n",
    "    \n",
    "    for i in range(time_steps, len(y_test_scaled)):\n",
    "        X_test.append(y_test_scaled[i-time_steps:i, :])\n",
    "    \n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], n_features))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, sc, target_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hp.Int('units_1', min_value=128, max_value=320, step=64),\n",
    "                   activation='tanh',\n",
    "                   return_sequences=True, \n",
    "                   input_shape=(None, n_features)))\n",
    "    \n",
    "    model.add(LSTM(units=hp.Int('units_2', min_value=64, max_value=256, step=32),\n",
    "                   activation='tanh',\n",
    "                   return_sequences=False))\n",
    "\n",
    "    model.add(Dense(units=hp.Int('dense_unit', min_value=16, max_value=128, step=16),\n",
    "                    activation='tanh'))\n",
    "        \n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mse'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def optimize_model(X_train, y_train, X_test, sc, epochs, trials, target_idx):\n",
    "   \n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        tuner = RandomSearch(\n",
    "            build_model,\n",
    "            objective='loss',\n",
    "            max_trials= trials,\n",
    "            directory=temp_dir,\n",
    "            project_name='temp_project')\n",
    "\n",
    "    tuner.search_space_summary()\n",
    "    tuner.search(X_train, y_train,\n",
    "                 epochs=epochs,\n",
    "                 batch_size=8)\n",
    "\n",
    "    tuner.results_summary()\n",
    "\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "    pred = best_model.predict(X_test) \n",
    "    pred_norm = pred \n",
    "    \n",
    "    pred_expanded = np.zeros((pred.shape[0], n_features))\n",
    "    pred_expanded[:,target_idx] = pred.ravel()  \n",
    "\n",
    "    pred = sc.inverse_transform(pred_expanded)\n",
    "    pred = pred[:, target_idx]  \n",
    "    \n",
    "    best_model.summary()\n",
    "  \n",
    "    return best_model, pred, pred_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b315c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(best_model, product_code, idx):\n",
    "    path = f'./Result/EEMD+LSTM/Model/{product_code}_{idx}.h5'\n",
    "    best_model.save(path)\n",
    "    return \n",
    "\n",
    "def use_model(X_test, product_code, idx, target_idx, sc):\n",
    "    path = f'./Result/EEMD+LSTM/Model/{product_code}_{idx}.h5'\n",
    "    best_model = tf.keras.models.load_model(path)\n",
    "    \n",
    "    pred = best_model.predict(X_test) \n",
    "    pred_norm = pred \n",
    "    \n",
    "    pred_expanded = np.zeros((pred.shape[0], n_features))\n",
    "    pred_expanded[:,target_idx] = pred.ravel()  \n",
    "    \n",
    "    pred = sc.inverse_transform(pred_expanded)\n",
    "    pred = pred[:, target_idx]  \n",
    "    \n",
    "    best_model.summary()\n",
    "\n",
    "    return best_model, pred, pred_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a404016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EEMD_LSTM(product_df, all_eIMFs_dict, time_steps, epochs, trials, saved_model: bool):\n",
    "    residue_epochs = epochs\n",
    "    pred_dict = {}\n",
    "    product_code = product_df['Product'].unique()[0]\n",
    "     \n",
    "    for idx, i in enumerate(all_eIMFs_dict.keys()):\n",
    "        print(f'--------Total: 0~{len(all_eIMFs_dict)-1} eIMFs, Now: {i} --------')\n",
    "        \n",
    "        eIMF_df = all_eIMFs_dict[i]\n",
    "\n",
    "        X_train, y_train, X_test, y_test, sc, target_idx = split_data(product_df, eIMF_df, time_steps)\n",
    "        \n",
    "        # use the existing model\n",
    "        if saved_model:\n",
    "            best_model, pred, pred_norm = use_model(X_test, product_code, idx, target_idx, sc)\n",
    "        # save the new model\n",
    "        else:\n",
    "            best_model, pred, pred_norm = optimize_model(X_train, y_train, X_test, sc, epochs, trials, target_idx)\n",
    "            save_model(best_model, product_code, idx)\n",
    "        \n",
    "        if idx != len(all_eIMFs_dict)-2:\n",
    "            epochs = max(1, round(epochs * 0.8)) \n",
    "      \n",
    "        else: \n",
    "            epochs = residue_epochs\n",
    "        \n",
    "        y_test.reset_index(drop=True, inplace=True)\n",
    "        pred_df = pd.DataFrame({'Pred': pred.reshape(-1) ,'Pred_norm': pred_norm.reshape(-1)})\n",
    "        res_df = pd.concat([y_test, pred_df], axis=1)\n",
    "        \n",
    "        res_df.set_index('Date', inplace=True)\n",
    "        res_df.index = pd.to_datetime(res_df.index)\n",
    "        # res_df: ['y', 'y_norm', 'Pred', 'Pred_norm'], index='Date'\n",
    "        pred_dict[i] = res_df\n",
    "        \n",
    "    return pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40503729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_result_df(pred_dict):\n",
    "    all_eIMF_df = pd.DataFrame()\n",
    "    for tmp_df in pred_dict.values():\n",
    "        all_eIMF_df = pd.concat([all_eIMF_df, tmp_df], axis=1)\n",
    "        \n",
    "    pred_df = all_eIMF_df['Pred'].sum(axis=1)\n",
    "    actual_df = all_eIMF_df['y'].sum(axis=1)\n",
    "    \n",
    "    all_result_df = pd.DataFrame({'Pred': pred_df, 'y': actual_df})\n",
    "    all_result_df.loc[all_result_df['Pred']<0, 'Pred']=0 \n",
    "    \n",
    "    return all_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8fe2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_pred_plot(product_code, pred_dict, all_result_df, metric_df):\n",
    "    \"\"\"\n",
    "    Plot the actual vs predition and save the figure in the given directory\n",
    "    \"\"\"\n",
    "    pred_dict['all_result'] = all_result_df\n",
    "    \n",
    "    save_path = os.path.join(\"Result\", \"EEMD+LSTM\", product_code)\n",
    "        \n",
    "    for i, res_df in enumerate(pred_dict.values()):\n",
    "        img_n = len(pred_dict)\n",
    "        title = f\"eIMF{i+1}\"\n",
    "        if i == img_n-2: title = \"Residue\"\n",
    "        actual = res_df['y']\n",
    "        pred = res_df['Pred']\n",
    "        save_name = f'{product_code}_eIMF_{i+1}'\n",
    "        \n",
    "        if i == img_n-1: # All result\n",
    "            title = f\"{product_code}-All Result\"\n",
    "            save_name = f'{product_code}_all_result'\n",
    "\n",
    "        # Pred-Actual Plot\n",
    "        plt.figure(figsize=(16, 8), dpi=300)\n",
    "        plt.title(title, fontsize=20)\n",
    "        plt.xlabel(\"Date\", fontsize=14)\n",
    "        plt.ylabel(\"Order Demand\", fontsize=14)\n",
    "        plt.plot(res_df.index, actual, label ='Actual', color='r')\n",
    "        plt.plot(res_df.index, pred, label='Prediction',color='b')\n",
    "\n",
    "        plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
    "        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        \n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        \n",
    "        plt.savefig(os.path.join(save_path, save_name+'.png'), dpi=300)\n",
    "        plt.show()\n",
    "        \n",
    "    metric_df.to_csv(os.path.join(save_path, f'{product_code}_metric.csv'), encoding=\"utf-8-sig\")\n",
    "    all_result_df.to_csv(os.path.join(save_path, f'{product_code}_total_result.csv'), encoding=\"utf-8-sig\")\n",
    "    \n",
    "    del pred_dict['all_result']\n",
    "    \n",
    "    file_path = os.path.join(save_path, f'{product_code}_eIMF_dict.pkl')\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(pred_dict, file)\n",
    "        \n",
    "    plt.close('all') # close all figures to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / (actual+1)))\n",
    "\n",
    "def nrmse(y_true, y_pred):\n",
    "    mse = root_mean_squared_error(y_true, y_pred)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nrmse = mse / target_mean\n",
    "    return nrmse\n",
    "\n",
    "def nmae(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    target_mean = np.mean(y_true)\n",
    "    nmae = mae / target_mean\n",
    "    return nmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83451baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(pred_df):\n",
    "    metric_df = pd.DataFrame(columns=['MAPE',\n",
    "                                      'RMSE',\n",
    "                                      'MAE',\n",
    "                                      'NRMSE',\n",
    "                                      'NMAE',\n",
    "                                      'R2'])\n",
    "   \n",
    "    actual = pred_df['y']\n",
    "    pred = pred_df['Pred']\n",
    "\n",
    "\n",
    "    MAPE = mape(actual, pred) \n",
    "    RMSE = root_mean_squared_error(actual, pred) \n",
    "    MAE = mean_absolute_error(actual,pred) \n",
    "    NRMSE = nrmse(actual,pred) \n",
    "    NMAE = nmae(actual,pred) \n",
    "    R2 = r2_score(actual, pred)\n",
    "\n",
    "    tmp_df = pd.DataFrame({'MAPE':[round(MAPE, 4)],\n",
    "                           'RMSE':[round(RMSE, 4)],\n",
    "                           'MAE':[round(MAE, 4)],\n",
    "                           'NRMSE':[round(NRMSE, 4)],\n",
    "                           'NMAE':[round(NMAE, 4)],\n",
    "                           'R2': [round(R2, 4)]})\n",
    "\n",
    "    metric_df = pd.concat([metric_df, tmp_df])\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e560ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_metric_df(pred_dict, all_result_df):\n",
    "\n",
    "    metric_df = pd.DataFrame(columns=['MAPE', 'RMSE', 'MAE', 'NRMSE', 'NMAE', 'R2'])\n",
    "    for i, pred_df in pred_dict.items():\n",
    "        imf_df = calculate_metrics(pred_df)\n",
    "        metric_df = pd.concat([metric_df, imf_df])\n",
    "    \n",
    "    imf_idx = pd.Index(['eIMF_'+str(i+1) for i in range(len(pred_dict))]) # changed result_dict to pred_dict\n",
    "    metric_df.index = imf_idx # Assign the created index to metric_df\n",
    "    \n",
    "    metric_df = pd.concat([metric_df, calculate_metrics(all_result_df)], axis=0)\n",
    "    metric_df = metric_df.rename(index={metric_df.index[-1]: 'All'}) \n",
    "    \n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce9ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_EEMD_LSTM(product_code, time_steps=30, epochs=50, optimize_trials=5):\n",
    "    start_time = time.time()\n",
    "    product_df = df[df['Product']== product_code].reset_index(drop=True)\n",
    "    \n",
    "    all_eIMFs_df, nIMFs = eemd_fit(product_df)\n",
    "    all_eIMFs_dict = extract_eIMFs(all_eIMFs_df, nIMFs)\n",
    "    \n",
    "    pred_dict = EEMD_LSTM(product_df, all_eIMFs_dict, time_steps, epochs, optimize_trials, saved_model=True) #dictionary, time_steps, epochs\n",
    "    # save_model(product_code, model_dict)\n",
    "    all_result_df = make_all_result_df(pred_dict)\n",
    "    \n",
    "    # Metric 성능 평가\n",
    "    metric_df = make_metric_df(pred_dict, all_result_df)\n",
    "    # Pred_Actual Plot\n",
    "    actual_pred_plot(product_code, pred_dict, all_result_df, metric_df)\n",
    "    \n",
    "    # 실행시간 확인\n",
    "    elapsed_time_seconds = time.time() - start_time\n",
    "    elapsed_time_minutes = elapsed_time_seconds / 60\n",
    "    print(\"실행 시간: {:.2f} 분\".format(elapsed_time_minutes))\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5269ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b0091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Data/dataset.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25559e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "set_seed(1234)\n",
    "    \n",
    "all_metric = pd.DataFrame()\n",
    "target_code = ['Office Product', 'Packaging material', 'Pharmaceuticals']\n",
    "for code in target_code:\n",
    "   \n",
    "    print(\"==================================\")\n",
    "    print(f\"============ { code } ============\")\n",
    "    print(\"==================================\")\n",
    "\n",
    "    tmp_metric = execute_EEMD_LSTM(code)\n",
    "    all_metric = pd.concat([all_metric, tmp_metric])\n",
    "    \n",
    "prod_metric_df = all_metric.loc['All']\n",
    "prod_metric_df.index = target_code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eemd",
   "language": "python",
   "name": "eemd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
